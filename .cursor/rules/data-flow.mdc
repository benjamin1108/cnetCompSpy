---
description: 
globs: 
alwaysApply: true
---
# 数据流和目录结构

## 数据目录结构

项目使用以下目录结构组织数据：

```
data/
  ├── raw/              # 爬虫爬取的原始数据
  │   ├── aws/          # AWS原始数据
  │   │   ├── blog/     # 博客文章
  │   │   └── whatsnew/ # 产品更新
  │   ├── azure/        # Azure原始数据
  │   └── gcp/          # Google Cloud原始数据
  │
  └── analysis/         # AI分析生成的数据
      ├── aws/          # AWS分析结果
      ├── azure/        # Azure分析结果
      └── gcp/          # GCP分析结果
```

## 数据流程

1. **爬取阶段**：
   - 爬虫管理器（[crawler_manager.py](mdc:src/crawlers/common/crawler_manager.py)）根据配置启动相应的爬虫
   - 爬虫从云服务提供商网站爬取数据，保存为HTML或其他格式
   - 元数据管理器（[metadata_manager.py](mdc:src/utils/metadata_manager.py)）记录爬取历史，用于增量更新

2. **分析阶段**：
   - AI分析器（[analyzer.py](mdc:src/ai_analyzer/analyzer.py)）读取原始数据
   - 使用配置的AI模型处理文本内容，提取关键信息
   - 分析结果以JSON格式保存在analysis目录中

3. **统计和报告阶段**：
   - 统计分析工具（[stats_analyzer.py](mdc:src/utils/stats_analyzer.py)）汇总分析结果
   - 生成统计报告和竞争情报见解

## 缓存和历史数据

项目使用元数据文件（.metadata.json）跟踪已爬取的内容，实现增量更新：

- 记录每个URL的爬取时间和MD5哈希值
- 仅爬取新内容或更改过的内容
- `--force`参数可覆盖此机制，强制重新爬取所有内容

元数据管理器（[metadata_manager.py](mdc:src/utils/metadata_manager.py)）负责维护这些记录。
