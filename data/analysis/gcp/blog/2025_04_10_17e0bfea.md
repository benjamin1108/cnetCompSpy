
<!-- AI_TASK_START: AI标题翻译 -->
[新产品/新功能] Google Cloud 网络的最新创新

<!-- AI_TASK_END: AI标题翻译 -->


<!-- AI_TASK_START: AI竞争分析 -->
# 产品功能分析

## 新功能/新产品概述  
Google Cloud 最近发布的网络创新旨在应对AI时代的需求，**核心定义**为提供高性能、安全且可扩展的网络解决方案。**目标**是帮助企业构建分布式AI应用，提升网络能力以支持AI模型的训练、推理和服务。  
**背景**：随着AI的快速发展，企业面临海量数据处理、网络延迟和安全威胁的挑战。该系列创新基于Google Cloud Next 2025的发布，针对AI优化网络、简化服务网络和零信任安全等场景，**目标用户群**包括AI开发者和大型企业，**市场定位**是差异化竞争，通过全球基础设施优势超越传统网络方案，如AWS或Azure的类似产品。

## 关键客户价值  
- **成本优化**：如GKE Inference Gateway可**降低服务成本** _高达30%_，通过智能负载均衡和动态请求路由实现高效资源利用，与传统Kubernetes方案相比，显著减少了不必要的计算开销，但需注意冷启动可能带来的临时延迟。  
- **性能提升**：新功能支持**400G Cloud Interconnect**，提供4倍带宽加速数据摄取，提升AI训练效率；同时，**Cloud WAN** 可实现全球连接性能提升 _高达40%_，相比公共互联网，减少延迟并提升可靠性，适用于高并发AI应用场景，帮助企业如Snap和Goldman Sachs实现更快迭代。  
- **安全与可靠性**：引入**零信任RDMA安全**和**DNS Armor**，增强对AI流量和数据泄露的保护，与竞品相比（如Azure Firewall），Google Cloud的方案在DDoS防护上**效能提升24倍**，简化了多云环境的安全管理，但在大规模部署中可能增加政策配置的复杂度。  
  - 在AI推理场景中，GKE Inference Gateway的**尾延迟降低60%** 和**吞吐量提升40%**，让企业避免传统IaaS架构的瓶颈，差异化优势在于与NVIDIA等伙伴的深度集成，提供端到端保护。

## 关键技术洞察  
- **技术独特性**：基于**EventBridge规则引擎**和**RDMA网络**，实现了高吞吐低延迟的GPU间通信，支持**非阻塞配置**达3.2Tbps，工作原理是通过动态路由和防火墙策略，确保AI工作负载的实时处理。该创新点在于**AI优化网络**，如400G Interconnect的带宽扩展，显著提升大规模集群（支持30,000 GPUs）的可扩展性。  
- **对性能、安全性影响**：这些技术提高了**可用性**，如Cloud CDN的快速缓存无效化减少了Web应用延迟，但挑战包括管理复杂性——例如，**Service Extensions**的WebAssembly插件虽允许边缘编程，但可能引入兼容性问题，需要额外开发努力。相比传统方案，Google Cloud的**异步批处理机制**在高并发下优化资源利用，但冷启动延迟仍是潜在局限，需要结合**CloudWatch指标**进行动态调整。  
- **创新点与挑战**：**GKE Inference Gateway**的智能负载均衡基于Google Jetstream算法，减少了AI推理成本，但实现挑战在于跨云集成（如NVIDIA GPU），可能面临第三方兼容性和数据隐私风险；总体上，该方案在AI安全方面通过**Model Armor**和第三方集成（如Palo Alto Networks）增强防护，体现了Google Cloud在零日威胁下的领先性。

## 其他信息  
- **生态扩展**：Google Cloud通过**Network Security Integration**与Imperva等伙伴合作，增强了安全生态的灵活性，提供无缝多云连接，但用户需评估集成成本以避免潜在的性能开销。  
- **未来趋势**：这些创新响应了AI时代对全球网络的需求，如**Cloud WAN**的TCO降低 _高达40%_，预计将推动企业从自定义WAN向托管解决方案转型，体现了Google在行业趋势中的前瞻性。

<!-- AI_TASK_END: AI竞争分析 -->


<!-- AI_TASK_START: AI全文翻译 -->
# Google Cloud 网络的最新动态

**原始链接:** [https://cloud.google.com/blog/products/networking/networking-innovations-at-google-cloud-next25](https://cloud.google.com/blog/products/networking/networking-innovations-at-google-cloud-next25)  

**发布时间:** 2025-04-10  

**厂商:** GCP  

**类型:** BLOG  

---  
网络  

#  

What’s new with Google Cloud networking  

2025 年 4 月 10 日  

  

![https://storage.googleapis.com/gweb-cloudblog-publish/images/AI-optimized_Networking.max-2500x2500.jpg](https://storage.googleapis.com/gweb-cloudblog-publish/images/AI-optimized_Networking.max-2500x2500.jpg)  

##### Muninder Sambi  

VP, Cloud Networking  

##### Rob Enns  

VP & GM, Cloud Networking  

##### 试用 Gemini 2.5  

我们最智能的模型现已在 Vertex AI 上可用  

[试用 now](https://console.cloud.google.com/vertex-ai/studio/freeform)  

AI 时代已经到来，它正在从根本上重塑各行各业，并对网络能力提出前所未有的需求，用于训练、推理和部署 AI 模型。为了推动这一变革，组织需要全球网络解决方案，能够处理海量容量、实现无缝连接，并提供强大的安全性。  

在 Next 25 上，我们正在解决这些关键需求，并通过云网络产品和 [Cross-Cloud Network (Cross-Cloud Network)](https://cloud.google.com/solutions/cross-cloud-network) 解决方案的创新套件，帮助客户轻松构建和交付分布式 AI 应用。  

这些创新包括 AI 优化网络 (AI-optimized networking)、简化的安全服务网络，以及针对零日威胁的零信任安全。我们还在扩展 Cross-Cloud Network 解决方案，以包含全球前端的可编程性和性能，用于 Web、媒体和生成式 AI (Generative AI) 服务，此外还有我们的最新解决方案 [Cloud WAN (Cloud WAN)](https://cloud.google.com/blog/products/networking/connect-globally-with-cloud-wan-for-the-ai-era)，它提供了一个完全托管的全球网络，用于跨企业位置的 sécurisé 和简化连接，利用我们广泛的全球基础设施。  

### AI 优化网络：高性能、安全、可扩展  

为了让您的 AI 模型发挥最佳效果，您需要一个能够处理海量数据和密集处理的网络。无论您是在训练大型模型还是为用户提供服务（“推理”），速度、可靠性和安全性都是必不可少的。您要处理复杂的基础设施，并移动大量数据以提供闪电般的响应。我们的创新专注于为这些 demanding AI 工作负载提供所需的基础设施：  

  * **海量数据摄取：使用 400G Cloud Interconnect 和 Cross-Cloud Interconnect：** 通过 4 倍于 100G Cloud Interconnect 和 Cross-Cloud Interconnect 的带宽，更快地导入 AI 数据集，并在跨云环境中训练，提供从本地或其它云环境到 Google Cloud 的连接。本功能将于今年晚些时候可用。  

  * **前所未有的集群规模：** 使用支持非阻塞配置的网络，在每个集群中构建高达 30,000 个 GPU (Graphics Processing Units) 的海量 AI 服务，现已进入预览。  

  * **零信任 RDMA 安全：** 通过我们的 RDMA 防火墙保护高性能 GPU 和 TPU (Tensor Processing Units) 流量，采用动态执行策略实现零信任网络 (zero-trust networking)。本功能将于今年晚些时候可用。  

  * **加速 GPU 到 GPU 通信：** 通过高吞吐、低延迟的 RDMA 网络 (RDMA networking)，释放高达 3.2Tbps 的非阻塞 GPU 到 GPU 带宽，现已正式可用。  

“Google Cloud 在我们的 AI 基础设施中发挥关键作用，支持我们以大规模方式为用户交付高性能和安全 AI 体验，同时优化资源利用。” - Xu Ning, Dir of Engineering, AI Platform, Snap, Inc.  

AI 推理的日益复杂，特别是当企业部署多个任务优化模型时，会带来显著的网络挑战。AI 容量需求的增长会给网络基础设施带来压力，因为高效地将数据路由到分布在各区域的 GPU 或 TPU 资源需要高带宽和低延迟。此外，生成式 AI (Generative AI) 应用和代理的引入会扩大攻击面，在推理过程中导致敏感数据泄露的风险，因此需要强大的 AI 安全和安全措施。为应对这些挑战，我们正在推出 GKE Inference Gateway，现已进入预览，它提供：  

  * **针对生成式 AI 应用的差异化性能**，而无需高昂的服务成本。 [GKE Inference Gateway (GKE Inference Gateway)](https://cloud.google.com/kubernetes-engine/docs/concepts/about-gke-inference-gateway) 中的新功能 **可将服务成本降低多达 30%、尾部延迟降低多达 60%、吞吐量提高多达 40%**，相比其它托管和开源 Kubernetes 解决方案（基于内部基准测试）。功能包括基于 Google Jetstream、NVIDIA 和 vLLM 的模型服务器指标的智能负载均衡、动态请求路由，以及高效的动态 LoRA 微调模型。  

  * **AI 安全和防护**，通过强大的新集成。现在，您可以使用 GKE Inference Gateway 和 Cloud Load Balancing，与 Model Armor、NVIDIA NeMo Guardrails 以及 Palo Alto Networks AI Runtime Security 结合。这种方法利用 [Service Extensions (Service Extensions)](https://cloud.google.com/service-extensions/docs/overview) 为您的 AI 模型提供全面保护，简化平台工程和安全团队的治理。  

  * **针对 LLM 推理的 Google Cloud Load Balancing 优化**，让您利用 NVIDIA GPU 容量跨多个云提供商或本地基础设施。  

“各行业的企业都在寻求全栈集成基础设施，以安全且经济高效的方式部署代理式 AI。通过将 NVIDIA 推理软件用于实时可观察性以及 NeMo Guardrails 用于强大安全执行，与 GKE Inference Gateway 集成，NVIDIA 和 Google Cloud 正在提供先进的性能和可靠性提升 AI 部署的能力。” - Kari Briski, vice president of generative AI software for Enterprise, NVIDIA  

### 可编程的全球前端，用于 Web、媒体和 AI  

Cross-Cloud Network 全球前端解决方案可加速和保护最 demanding 的 Web、媒体以及如今的生成式 AI (Generative AI) 应用，无论您的后端托管在哪里，都无需将基础设施暴露在互联网上。今天，我们为现代和生成式 AI 应用引入新创新：  

  * **边缘可编程性：使用 Service Extensions：** 通过 Service Extensions 插件解锁边缘的开放可编程性，由 WebAssembly (Wasm) 提供支持。使用超过 60 个 Rust、C++ 和 Go 插件示例，自动化、扩展和自定义您的应用。Cloud Load Balancing 支持现已正式可用，Cloud CDN 支持将于今年晚些时候跟进。  

  * **加速 Web 性能：** 通过 Cloud CDN 的快速缓存失效，在全球范围内交付静态和动态内容，并通过 TLS 1.3 0-RTT 提升已恢复连接的应用性能。这两个功能现已进入预览。  

  * **端到端 mTLS 安全：** 通过 Cloud Load Balancing 加强安全态势，使用端到端 mTLS 保护从客户端到后端基础设施的数据。客户端到前端 mTLS 于去年推出，后端 mTLS 现已进入预览。  

“Service Extensions 插件让我们能够通过轻松在请求/响应路径中运行自定义代码来自定义 Web 服务。基于开放标准如 WebAssembly 的边缘可编程解决方案，并提供大量现成示例，让我们的开发人员能够快速满足业务自定义需求。” - Justin Reid, Principal Engineer, Shopify  

### 服务中心网络简化开发  

无论您是在构建前沿生成式 AI 应用还是现代化现有系统，服务中心架构 (service-centric architectures) 都是快速迭代的关键。作为服务中心架构的先驱，我们致力于帮助 NetOps、DevOps、SecOps 和开发团队简化服务部署和管理。通过抽象底层网络和安全层面的复杂性，我们让开发人员能够快速部署、更新和保护跨多个应用的服務。今天，我们正在推出增强的服务中心网络 (service-centric networking) 中的新自动化、安全和规模创新：  

  * **简化的服务发现和管理。** App Hub 集成通过自动化服务发现和目录简化生产者-消费者交互。服务健康（将于今年晚些时候推出）可实现弹性全球服务，支持网络驱动的跨区域故障转移。  

  * **简化的多网络、多服务、多计算部署。** 在 2025 年晚些时候，您可以使用 [Private Service Connect (Private Service Connect)](https://cloud.google.com/vpc/docs/private-service-connect) 在单个 GKE 集群中发布多个服务，让它们从非对等 GKE 集群、Cloud Run 或 Service Mesh 中原生访问。  

“我们的 Google 合作让我们简化服务发现，并帮助开发人员更快、更高效地迭代。” - Jonathan Perry, Partner, Engineering, Goldman Sachs  

### 保护现代和生成式 AI 应用免受演变攻击  

我们目睹了复杂攻击的激增：太比特级 DDoS、DNS 隧道用于数据外泄，以及越来越多的 AI 驱动威胁，这些威胁规避传统防御。这些网络风险要求在网络安全方法上进行根本性转变，并强调需要超越传统周边防御的先进网络安全能力。今天，我们宣布强大的网络安全增强措施，为您的分布式多云应用和面向互联网的服务提供全面保护。  

我们的策略有三个核心支柱：  

![https://storage.googleapis.com/gweb-cloudblog-publish/images/image1_ec6qD22.max-500x500.png](https://storage.googleapis.com/gweb-cloudblog-publish/images/image1_ec6qD22.max-500x500.png)  

## **保护工作负载：全球规模 DDoS 保护，提供高达 24 倍的威胁效能**  

保护您的分布式应用和面向互联网的服务免受关键网络攻击向量的侵害至关重要。今天，我们引入几个关键增强措施：  

  * **DNS Armor (DNS Armor)：** DNS 流量通常缺乏足够的监控，使其成为数据外泄的首要目标。攻击者利用这一盲点，通过 DNS 隧道、域名生成算法 (DGA) 和其它复杂技术绕过传统安全控件。由 Infoblox Threat Defense 提供支持，每天监控 70 亿 DNS 事件，DNS Armor 可检测这些基于 DNS 的数据外泄攻击。本功能将于今年晚些时候进入预览。  

  * **增强的安全态势执行：** 使用 **新的 Cloud Armor 分层策略** 加强全组织一致保护。通过 **新的网络类型** 和 **新的 Cloud NGFW 分层防火墙策略的防火墙标签**，在不依赖网络架构的情况下强制执行粒度保护，本季度进入预览。  

  * 在 2024 年，我们推出了 Cloud NGFW Enterprise，其效能比其它主要公共云高出高达 24 倍。我们将继续改进 Cloud NGFW，通过 **新的第 7 层域名过滤**，让防火墙管理员监控和控制出站 Web 流量，仅限于允许的目的地，本功能将于 2025 年晚些时候推出。  

“我们使用 Cloud NGFW 和 Cloud Armor 来保护 Google Cloud 中的关键应用和网站。在 Next 上宣布的新网络安全创新将帮助我们提升用户保护并简化网络安全管理。” - Jason Jones, Sr. Director, Security Engineering, UKG  

## **保护数据：引入内联网络 DLP**  

在当今数据驱动的世界中，企业知识产权是最宝贵的资产。但确保其安全和合规可能很复杂。我们理解需要在静态数据和传输中数据实现强大且简化的数据丢失预防 (DLP)。即将推出的 **内联网络 DLP (inline network DLP)** 用于 Secure Web Proxy 和 Application Load Balancer，通过与第三方解决方案（如 Symantec DLP）的 [Service Extensions (Service Extensions)](https://cloud.google.com/service-extensions/docs/overview) 集成，为敏感传输中数据提供 **实时保护**。本季度进入预览，内联网络 DLP 可帮助您保护关键数据并维护合规，而不牺牲性能或敏捷性。  

## **开放安全生态：第三方安全插入**  

我们让您灵活选择首选安全解决方案，针对特定需求定制保护。我们很高兴扩展我们的安全合作伙伴生态系统，通过更深度的集成。最近，我们宣布您可以通过 [Network Security Integration (Network Security Integration)](https://cloud.google.com/blog/products/networking/introducing-network-security-integration) 将合作伙伴网络服务或虚拟设备插入 Google Cloud 工作负载，现已正式可用，这有助于在混合和多云环境中维护一致策略，而无需更改路由策略或网络架构。  

此外，为了扩展我们的 Web 和 API 保护生态，我们与 Imperva 合作，将 Imperva Application Security 与 Cloud Load Balancing 集成，也通过 [Service Extensions (Service Extensions)](https://cloud.google.com/service-extensions/docs/overview)，并已在 Google Cloud Marketplace 上可用。  

### Cloud WAN：AI 时代的企业骨干网  

连接现代业务极其复杂。客户必须处理许多不同的网络和安全架构，并权衡可靠性、应用速度和成本。这可能导致复杂的自定义解决方案，难以管理、削弱安全态势，并且往往无法提供最佳结果。Cloud WAN，我们最新的 Cross-Cloud Network 解决方案，是一个完全托管的、可靠且安全的企业骨干网，用于转型企业 WAN 架构并解决这些挑战。  

Cloud WAN 提供显著优势：  

  * Cloud WAN 与使用联合托管设施的客户管理 WAN 解决方案相比，可节省高达 40% 的总拥有成本 (TCO)¹  

  * 通过 Google 扩展骨干网络实现全球覆盖和性能，提供 99.99% 的可靠性  

  * Cross-Cloud Network 与公共互联网相比，性能提升高达 40%²  

  * 与主要 SD-WAN 和安全供应商的开放、灵活且紧密集成生态  

更多细节，请阅读完整公告 [here](https://cloud.google.com/blog/products/networking/connect-globally-with-cloud-wan-for-the-ai-era)。  

### 一个网络来交付 AI 时代  

我们的云网络产品和解决方案让您能够跨全球连接、简化、现代化和保护您的组织。通过这些新创新 — 加上 [新的 Cloud WAN (Cloud WAN)](https://cloud.google.com/blog/products/networking/connect-globally-with-cloud-wan-for-the-ai-era?e=48754805) — 我们继续为您提供适应新技术、服务、应用和位置的灵活性，所有这些都具备 AI 时代所需的敏捷性。  

了解更多 Google Cloud Next 2025 公告，您可以观看我们的 [Cross-Cloud Network 创新会议](https://cloud.withgoogle.com/next/25/session-library?session=BRK2-029&utm_source=copylink&utm_medium=unpaidsoc&utm_campaign=FY25-Q2-global-EXP106-physicalevent-er-next25-mc&utm_content=reg-is-live-next-homepage-social-share&utm_term=-)，并查看许多优秀的网络 [专题会议](https://cloud.withgoogle.com/next/25/session-library?filters=session-type-breakouts,interest-networking#all)。  

* * *  

*1\. 架构包括 SD-WAN 和第三方防火墙，并将客户管理 WAN（使用多站点联合托管设施）与由 Google Cloud 管理并托管的 WAN 进行比较。  
2\. 在测试中，当流量通过 Cross-Cloud Network 传输到目标时，与通过公共互联网传输到同一目标的流量相比，网络延迟降低了超过 40%。*  

发布在  

  * [网络 (Networking)](https://cloud.google.com/blog/products/networking)  
  * [Google Cloud Next (Google Cloud Next)](https://cloud.google.com/blog/topics/google-cloud-next)

<!-- AI_TASK_END: AI全文翻译 -->

